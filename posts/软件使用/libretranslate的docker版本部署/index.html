<!DOCTYPE html>
<html lang="zh" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>本地docker部署libretranslate翻译模型并采用CUDA加速 | Xu Qianchao&#39;s Blog</title>
<meta name="keywords" content="AI, 翻译, 阅读工具, docker部署">
<meta name="description" content="Libtranslate的本地部署，并采用CUDA加速">
<meta name="author" content="xuqianchao">
<link rel="canonical" href="https://againwq.github.io/posts/%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/libretranslate%E7%9A%84docker%E7%89%88%E6%9C%AC%E9%83%A8%E7%BD%B2/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.be2b9394d18952a10663627c3ba44fc9d3a0c79ef4e44d7d15193eb168e1a0ea.css" integrity="sha256-viuTlNGJUqEGY2J8O6RPydOgx5705E19FRk&#43;sWjhoOo=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://againwq.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://againwq.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://againwq.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://againwq.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://againwq.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>

<script type="text/javascript" async
  src="https://cdn.bootcss.com/mathjax/2.7.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\[\[', '\]\]']],
        processEscapes: true,
        processEnvironments: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        TeX: {
          equationNumbers: { autoNumber: "AMS" },
          extensions: ["AMSmath.js", "AMSsymbols.js"]
        }
      }
    });

    MathJax.Hub.Queue(function () {
      
      
      
      var all = MathJax.Hub.getAllJax(), i;
      for (i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
    });
  </script>

<style>
  code.has-jax {
    font: inherit;
    font-size: 100%;
    background: inherit;
    border: inherit;
    color: #515151;
  }
</style>
<link rel="icon" href="/avatar.png">

<script defer crossorigin="anonymous" src="/assets/js/extended/custom.js"></script><meta property="og:title" content="本地docker部署libretranslate翻译模型并采用CUDA加速" />
<meta property="og:description" content="Libtranslate的本地部署，并采用CUDA加速" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://againwq.github.io/posts/%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/libretranslate%E7%9A%84docker%E7%89%88%E6%9C%AC%E9%83%A8%E7%BD%B2/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-11-12T00:00:00+00:00" />
<meta property="article:modified_time" content="2024-11-12T00:00:00+00:00" />


<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="本地docker部署libretranslate翻译模型并采用CUDA加速"/>
<meta name="twitter:description" content="Libtranslate的本地部署，并采用CUDA加速"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "系列",
      "item": "https://againwq.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  4 ,
      "name": "本地docker部署libretranslate翻译模型并采用CUDA加速",
      "item": "https://againwq.github.io/posts/%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/libretranslate%E7%9A%84docker%E7%89%88%E6%9C%AC%E9%83%A8%E7%BD%B2/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "本地docker部署libretranslate翻译模型并采用CUDA加速",
  "name": "本地docker部署libretranslate翻译模型并采用CUDA加速",
  "description": "Libtranslate的本地部署，并采用CUDA加速",
  "keywords": [
    "AI", "翻译", "阅读工具", "docker部署"
  ],
  "articleBody": "一、Libretanslate基本介绍 Libretanslate 是一个开源的，基于AI驱动的翻译软件，官方网站提供了在线的翻译功能，并且可以申请 api 密钥去调用 api 将翻译能力嵌入到我们自己的程序或者软件中。当然，官方的github有详细的本地部署教程，如果有能力建议根据官方的 README 部署，本文是对可能遇到的一些问题的补充。本文采用的是 docker 部署，当然官方提供了直接通过 pip 包部署，读者可以根据自己的需求选择。效果图如下：\n二. docker 与 nvidia docker 支持的前置条件 首先需要保证你的本地系统已经安装的 docker 环境，建议采用国内的源安装，比如清华源、阿里源等。同时建议配置docker镜像源防止由于网络问题无法拉取镜像。这里不提供安装配置命令，建议读者自行搜索相关资料。 使用 nvidia 的 docker 加速，需要读者本地拥有 nvidia 的显卡，并安装了显卡驱动。如果没有 nvidia 的显卡支持，可以跳过这一部分，进行 cpu 版本的本地部署。 首先要在自己的电脑上安装 nvidia docker 支持，参考的官方地址。根据你的 linux 发行版复制粘贴命令就行了，debian 发行版的安装命令如下：\n# 添加 apt 源 curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | \\ sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \u0026\u0026 \\ curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \\ sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \\ tee /etc/apt/sources.list.d/nvidia-container-toolkit.list sudo sed -i -e '/experimental/ s/^#//g' /etc/apt/sources.list.d/nvidia-container-toolkit.list # 更新源 sudo apt-get update # 安装nvidia-container-toolkit sudo apt-get install -y nvidia-container-toolkit 然后对 docker 进行配置：\nsudo nvidia-ctk runtime configure --runtime=docker sudo systemctl restart docker 三、docker版本的libretranslate的本地部署 接下来我们进行部署。首先，我们需要在 github 上下载源码：\ngit clone git@github.com:LibreTranslate/LibreTranslate.git 1. cpu版本libretranslate的部署 cpu 版本部署非常简单，在源码根路径下执行下面的命令\ndocker compose -f docker-compose.yml up -d --build 这个命令会根据 docker/Dockerfile 文件构建 libretranslate 镜像并部署在本地的 5000 端口。- -build 代表重新构建镜像。第一次构建好镜像后下一次可以把 - -build命令去掉，每次创建容器都会从网络上下载指定的翻译模型，因此 5000 端口并不能立即访问，可以通过 docker stats 查看容器的网络 IO 状态判断翻译模型是否下载完毕。\n2. GPU版本libretranslate的部署 部署gpu版本的 libretranslate 命令与上面相同，只是将 yml 文件为 docker-compose.cuda.yml。在部署之前，最好修改 docker/cuda.Dockerfile 文件将 cuda 的相关环境变量导出，大概在文件末尾的位置添加下面几行：\n# Depending on your cuda install you may need to uncomment this line to allow the container to access the cuda libraries # See: https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#post-installation-actions # ENV LD_LIBRARY_PATH=/usr/local/cuda/lib:/usr/local/cuda/lib64 ENV LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/lib64 ENV PATH=$PATH:/usr/local/cuda/bin ENV CUDA_HOME=/usr/local/cuda 然后通过 docker compose -f docker-compose.cuda.yml up -d --build进行构建并部署即可。同样的，构建成功 docker 会启动在本地 5000 端口，每次创建容器都会从网络上下载指定的翻译模型。\n四、可能遇到的问题 1. 构建镜像时apt和pip下载太慢 apt 和 pip 默认的官方源在国内访问不太稳定，可以在执行 apt install和 pip install之前更换镜像源为国内源，需要在对应的 Dockerfile中修改：\n# 更换apt源为清华源 RUN sed -i 's/archive.ubuntu.com/mirrors.tuna.tsinghua.edu.cn/g' /etc/apt/sources.list #更换pip源为清华源，应该添加在Dockerfile中pip下载之后的位置 RUN pip3 config set global.index-url https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple # cpu版本中Dockerfile采用了venv RUN ./venv/bin/pip config set global.index-url https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple 2. (URLError(ConnectionRefusedError(111, ‘Connection refused’)),)在 docker 日志中大量出现，无法下载翻译模型 Libretranslate 是基于 argos-translate 这个开源翻译模型开发的项目，内部仍然调用的是 argos-translate，argos-tanslate 下载一个 index.json 文件，然后根据你指定的需要支持的语言从 index.json 中获取下载路径。index.json 默认下载到 ~/.local/cache/argos-translate 翻译模型默认下载保存到当前路径下 db/session 下。我出现的问题是从 docker 内部是无法正常下载index.json的，但是主机是可以正常下载的，因此我采用的方法是手动下载 index.json 并将其放到 Libretranslate 源码根目录下，然后在我要构建的 Dockerfile 末尾修改为：\n# 将主机当前目录的index.json放到容器的/root/.local/cache/argos-translate/下 RUN mkdir -p /root/.local/cache/argos-translate/ RUN mv ./index.json /root/.local/cache/argos-translate/ EXPOSE 5000 # 原本的--host * 不知道为什么我会报错，这里改成 0.0.0.0就没有报错了 # 这里我只需要中英互译就可以了 ENTRYPOINT [\"libretranslate\", \"--host\", \"0.0.0.0\", \"--load-only\"，\"zh,en\"] 这是参考的解决方案的链接，这里提供我保存的index.json文件\n3. 启用 cuda 加速后进行翻译出现内部错误 建议先进入 docker 内部使用 python执行 torch.cuda.is_available() 查看 CUDA 是否成功支持。 这里我的问题是我的 nvidia 驱动版本是 debian12 默认下载的535, CUDA 版本最高支持到 12.2, 而且我本地的 CUDA 环境是 11.8。Libretranslate默认构建镜像的 CUDA 版本是 12.4, 版本过高导致 torch 调用硬件失败。解决的方法是将 Libretranslate 构建时采用的基础镜像从 FROM nvidia/cuda:12.4.1-devel-ubuntu20.04 更换为 FROM nvidia/cuda:12.2.0-devel-ubuntu20.04。 注意一定要是 12 版本以上的，我之前采用与本地相同的 11.8 启动仍然失败了，torch.cuda.is_available() 的返回值是 True，但是运行时会出现动态链接库找不到的问题，当前这个版本好像默认要求 CUDA 版本大于 12。\n参考文献 LibreTranslate的github 翻译模型下载失败参考解决方案 ",
  "wordCount" : "334",
  "inLanguage": "zh",
  "datePublished": "2024-11-12T00:00:00Z",
  "dateModified": "2024-11-12T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "xuqianchao"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://againwq.github.io/posts/%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/libretranslate%E7%9A%84docker%E7%89%88%E6%9C%AC%E9%83%A8%E7%BD%B2/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Xu Qianchao's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://againwq.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://againwq.github.io" accesskey="h" title="Xu Qianchao&#39;s Blog (Alt + H)">
                <img src="https://againwq.github.io/images/avatar.png" alt="" aria-label="logo"
                    height="35">Xu Qianchao&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://againwq.github.io/" title="主页">
                    <span>主页</span>
                </a>
            </li>
            <li>
                <a href="https://againwq.github.io/about/" title="关于">
                    <span>关于</span>
                </a>
            </li>
            <li>
                <a href="https://againwq.github.io/archives/" title="归档">
                    <span>归档</span>
                </a>
            </li>
            <li>
                <a href="https://againwq.github.io/posts/" title="系列">
                    <span>系列</span>
                </a>
            </li>
            <li>
                <a href="https://againwq.github.io/tags/" title="标签">
                    <span>标签</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://againwq.github.io">主页</a>&nbsp;»&nbsp;<a href="https://againwq.github.io/posts/">系列</a></div>
    <h1 class="post-title">
      本地docker部署libretranslate翻译模型并采用CUDA加速
    </h1>
    <div class="post-description">
      Libtranslate的本地部署，并采用CUDA加速
    </div>
    <div class="post-meta"><span title='2024-11-12 00:00:00 +0000 UTC'>2024-11-12</span>&nbsp;·&nbsp;2 分钟&nbsp;·&nbsp;334 字


</div>
  </header>
  <div class="tags-container">
    <ul class="post-tags">
      <li><a href="https://againwq.github.io/tags/ai/">AI</a></li>
      <li><a href="https://againwq.github.io/tags/%E7%BF%BB%E8%AF%91/">翻译</a></li>
      <li><a href="https://againwq.github.io/tags/%E9%98%85%E8%AF%BB%E5%B7%A5%E5%85%B7/">阅读工具</a></li>
      <li><a href="https://againwq.github.io/tags/docker%E9%83%A8%E7%BD%B2/">docker部署</a></li>
    </ul>
  </div> <aside id="toc-container" class="toc-container wide">
    <div class="toc">
        <details  open>
            <summary accesskey="c" title="(Alt + C)">
                <span class="details">目录</span>
            </summary>

            <div class="inner"><ul>
                    <li>
                        <a href="#%e4%b8%80libretanslate%e5%9f%ba%e6%9c%ac%e4%bb%8b%e7%bb%8d" aria-label="一、Libretanslate基本介绍">一、Libretanslate基本介绍</a></li>
                    <li>
                        <a href="#%e4%ba%8c-docker-%e4%b8%8e-nvidia-docker-%e6%94%af%e6%8c%81%e7%9a%84%e5%89%8d%e7%bd%ae%e6%9d%a1%e4%bb%b6" aria-label="二. docker 与 nvidia docker 支持的前置条件">二. docker 与 nvidia docker 支持的前置条件</a></li>
                    <li>
                        <a href="#%e4%b8%89docker%e7%89%88%e6%9c%ac%e7%9a%84libretranslate%e7%9a%84%e6%9c%ac%e5%9c%b0%e9%83%a8%e7%bd%b2" aria-label="三、docker版本的libretranslate的本地部署">三、docker版本的libretranslate的本地部署</a><ul>
                            
                    <li>
                        <a href="#1-cpu%e7%89%88%e6%9c%aclibretranslate%e7%9a%84%e9%83%a8%e7%bd%b2" aria-label="1. cpu版本libretranslate的部署">1. cpu版本libretranslate的部署</a></li>
                    <li>
                        <a href="#2-gpu%e7%89%88%e6%9c%aclibretranslate%e7%9a%84%e9%83%a8%e7%bd%b2" aria-label="2. GPU版本libretranslate的部署">2. GPU版本libretranslate的部署</a></li></ul>
                    </li>
                    <li>
                        <a href="#%e5%9b%9b%e5%8f%af%e8%83%bd%e9%81%87%e5%88%b0%e7%9a%84%e9%97%ae%e9%a2%98" aria-label="四、可能遇到的问题">四、可能遇到的问题</a><ul>
                            
                    <li>
                        <a href="#1-%e6%9e%84%e5%bb%ba%e9%95%9c%e5%83%8f%e6%97%b6apt%e5%92%8cpip%e4%b8%8b%e8%bd%bd%e5%a4%aa%e6%85%a2" aria-label="1. 构建镜像时apt和pip下载太慢">1. 构建镜像时apt和pip下载太慢</a></li>
                    <li>
                        <a href="#2-urlerrorconnectionrefusederror111-connection-refused%e5%9c%a8-docker-%e6%97%a5%e5%bf%97%e4%b8%ad%e5%a4%a7%e9%87%8f%e5%87%ba%e7%8e%b0%e6%97%a0%e6%b3%95%e4%b8%8b%e8%bd%bd%e7%bf%bb%e8%af%91%e6%a8%a1%e5%9e%8b" aria-label="2. (URLError(ConnectionRefusedError(111, &amp;lsquo;Connection refused&amp;rsquo;)),)在 docker 日志中大量出现，无法下载翻译模型">2. (URLError(ConnectionRefusedError(111, &lsquo;Connection refused&rsquo;)),)在 docker 日志中大量出现，无法下载翻译模型</a></li>
                    <li>
                        <a href="#3-%e5%90%af%e7%94%a8-cuda-%e5%8a%a0%e9%80%9f%e5%90%8e%e8%bf%9b%e8%a1%8c%e7%bf%bb%e8%af%91%e5%87%ba%e7%8e%b0%e5%86%85%e9%83%a8%e9%94%99%e8%af%af" aria-label="3. 启用 cuda 加速后进行翻译出现内部错误">3. 启用 cuda 加速后进行翻译出现内部错误</a></li>
                    <li>
                        <a href="#%e5%8f%82%e8%80%83%e6%96%87%e7%8c%ae" aria-label="参考文献">参考文献</a>
                    </li>
                </ul>
                </li>
                </ul>
            </div>
        </details>
    </div>
</aside>
<script>
    let activeElement;
    let elements;
    window.addEventListener('DOMContentLoaded', function (event) {
        checkTocPosition();

        elements = document.querySelectorAll('h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]');
         
         activeElement = elements[0];
         const id = encodeURI(activeElement.getAttribute('id')).toLowerCase();
         document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
     }, false);

    window.addEventListener('resize', function(event) {
        checkTocPosition();
    }, false);

    window.addEventListener('scroll', () => {
        
        activeElement = Array.from(elements).find((element) => {
            if ((getOffsetTop(element) - window.pageYOffset) > 0 && 
                (getOffsetTop(element) - window.pageYOffset) < window.innerHeight/2) {
                return element;
            }
        }) || activeElement

        elements.forEach(element => {
             const id = encodeURI(element.getAttribute('id')).toLowerCase();
             if (element === activeElement){
                 document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
             } else {
                 document.querySelector(`.inner ul li a[href="#${id}"]`).classList.remove('active');
             }
         })
     }, false);

    const main = parseInt(getComputedStyle(document.body).getPropertyValue('--article-width'), 10);
    const toc = parseInt(getComputedStyle(document.body).getPropertyValue('--toc-width'), 10);
    const gap = parseInt(getComputedStyle(document.body).getPropertyValue('--gap'), 10);

    function checkTocPosition() {
        const width = document.body.scrollWidth;

        if (width - main - (toc * 2) - (gap * 4) > 0) {
            document.getElementById("toc-container").classList.add("wide");
        } else {
            document.getElementById("toc-container").classList.remove("wide");
        }
    }

    function getOffsetTop(element) {
        if (!element.getClientRects().length) {
            return 0;
        }
        let rect = element.getBoundingClientRect();
        let win = element.ownerDocument.defaultView;
        return rect.top + win.pageYOffset;   
    }
</script>
  <div class="post-content"><h2 id="一libretanslate基本介绍">一、Libretanslate基本介绍<a hidden class="anchor" aria-hidden="true" href="#一libretanslate基本介绍">#</a></h2>
<p>   Libretanslate 是一个开源的，基于AI驱动的翻译软件，<a href="https://libretranslate.com/">官方网站</a>提供了在线的翻译功能，并且可以申请 api 密钥去调用 api 将翻译能力嵌入到我们自己的程序或者软件中。当然，<a href="https://github.com/LibreTranslate/LibreTranslate">官方的github</a>有详细的本地部署教程，如果有能力建议根据官方的 README 部署，本文是对可能遇到的一些问题的补充。本文采用的是 docker 部署，当然官方提供了直接通过 pip 包部署，读者可以根据自己的需求选择。效果图如下：</p>
<p><img loading="lazy" src="/images/Libretranslate%e7%bf%bb%e8%af%91%e6%95%88%e6%9e%9c.png" alt="libretranslate翻译效果"  />
</p>
<h2 id="二-docker-与-nvidia-docker-支持的前置条件">二. docker 与 nvidia docker 支持的前置条件<a hidden class="anchor" aria-hidden="true" href="#二-docker-与-nvidia-docker-支持的前置条件">#</a></h2>
<p>   首先需要保证你的本地系统已经安装的 docker 环境，建议采用国内的源安装，比如清华源、阿里源等。同时建议配置docker镜像源防止由于网络问题无法拉取镜像。这里不提供安装配置命令，建议读者自行搜索相关资料。</br>
   使用 nvidia 的 docker 加速，需要读者本地拥有 nvidia 的显卡，并安装了显卡驱动。如果没有 nvidia 的显卡支持，可以跳过这一部分，进行 cpu 版本的本地部署。</br>
   首先要在自己的电脑上安装 nvidia docker 支持，参考的<a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html">官方地址</a>。根据你的 linux 发行版复制粘贴命令就行了，debian 发行版的安装命令如下：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Shell" data-lang="Shell"><span class="line"><span class="cl"><span class="c1"># 添加 apt 源</span>
</span></span><span class="line"><span class="cl">curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey <span class="p">|</span> <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg <span class="o">&amp;&amp;</span> <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list <span class="p">|</span> <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>sed <span class="s1">&#39;s#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g&#39;</span> <span class="p">|</span> <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">sudo sed -i -e <span class="s1">&#39;/experimental/ s/^#//g&#39;</span> /etc/apt/sources.list.d/nvidia-container-toolkit.list
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 更新源</span>
</span></span><span class="line"><span class="cl">sudo apt-get update
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 安装nvidia-container-toolkit</span>
</span></span><span class="line"><span class="cl">sudo apt-get install -y nvidia-container-toolkit
</span></span></code></pre></div><p>   然后对 docker 进行配置：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Shell" data-lang="Shell"><span class="line"><span class="cl">sudo nvidia-ctk runtime configure --runtime<span class="o">=</span>docker
</span></span><span class="line"><span class="cl">sudo systemctl restart docker
</span></span></code></pre></div><h2 id="三docker版本的libretranslate的本地部署">三、docker版本的libretranslate的本地部署<a hidden class="anchor" aria-hidden="true" href="#三docker版本的libretranslate的本地部署">#</a></h2>
<p>   接下来我们进行部署。首先，我们需要在 github 上下载源码：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Shell" data-lang="Shell"><span class="line"><span class="cl">git clone git@github.com:LibreTranslate/LibreTranslate.git
</span></span></code></pre></div><h3 id="1-cpu版本libretranslate的部署">1. cpu版本libretranslate的部署<a hidden class="anchor" aria-hidden="true" href="#1-cpu版本libretranslate的部署">#</a></h3>
<p>   cpu 版本部署非常简单，在源码根路径下执行下面的命令</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Shell" data-lang="Shell"><span class="line"><span class="cl">docker compose -f docker-compose.yml up -d --build
</span></span></code></pre></div><p>   这个命令会根据 docker/Dockerfile 文件构建 libretranslate 镜像并部署在本地的 5000 端口。- -build 代表重新构建镜像。第一次构建好镜像后下一次可以把 - -build命令去掉，每次创建容器都会从网络上下载指定的翻译模型，因此 5000 端口并不能立即访问，可以通过 <code>docker stats</code> 查看容器的网络 IO 状态判断翻译模型是否下载完毕。</p>
<h3 id="2-gpu版本libretranslate的部署">2. GPU版本libretranslate的部署<a hidden class="anchor" aria-hidden="true" href="#2-gpu版本libretranslate的部署">#</a></h3>
<p>   部署gpu版本的 libretranslate 命令与上面相同，只是将 yml 文件为 docker-compose.cuda.yml。在部署之前，最好修改 docker/cuda.Dockerfile 文件将 cuda 的相关环境变量导出，大概在文件末尾的位置添加下面几行：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Shell" data-lang="Shell"><span class="line"><span class="cl"><span class="c1"># Depending on your cuda install you may need to uncomment this line to allow the container to access the cuda libraries</span>
</span></span><span class="line"><span class="cl"><span class="c1"># See: https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#post-installation-actions</span>
</span></span><span class="line"><span class="cl"><span class="c1"># ENV LD_LIBRARY_PATH=/usr/local/cuda/lib:/usr/local/cuda/lib64</span>
</span></span><span class="line"><span class="cl">ENV <span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span><span class="nv">$LD_LIBRARY_PATH</span>:/usr/local/cuda/lib64
</span></span><span class="line"><span class="cl">ENV <span class="nv">PATH</span><span class="o">=</span><span class="nv">$PATH</span>:/usr/local/cuda/bin
</span></span><span class="line"><span class="cl">ENV <span class="nv">CUDA_HOME</span><span class="o">=</span>/usr/local/cuda
</span></span></code></pre></div><p>   然后通过 <code>docker compose -f docker-compose.cuda.yml up -d --build</code>进行构建并部署即可。同样的，构建成功 docker 会启动在本地 5000 端口，每次创建容器都会从网络上下载指定的翻译模型。</p>
<h2 id="四可能遇到的问题">四、可能遇到的问题<a hidden class="anchor" aria-hidden="true" href="#四可能遇到的问题">#</a></h2>
<h3 id="1-构建镜像时apt和pip下载太慢">1. 构建镜像时apt和pip下载太慢<a hidden class="anchor" aria-hidden="true" href="#1-构建镜像时apt和pip下载太慢">#</a></h3>
<p>   apt 和 pip 默认的官方源在国内访问不太稳定，可以在执行 <code>apt install</code>和 <code>pip install</code>之前更换镜像源为国内源，需要在对应的 Dockerfile中修改：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Shell" data-lang="Shell"><span class="line"><span class="cl"><span class="c1"># 更换apt源为清华源</span>
</span></span><span class="line"><span class="cl">RUN sed -i <span class="s1">&#39;s/archive.ubuntu.com/mirrors.tuna.tsinghua.edu.cn/g&#39;</span>  /etc/apt/sources.list
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">#更换pip源为清华源，应该添加在Dockerfile中pip下载之后的位置</span>
</span></span><span class="line"><span class="cl">RUN pip3 config <span class="nb">set</span> global.index-url https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># cpu版本中Dockerfile采用了venv</span>
</span></span><span class="line"><span class="cl">RUN ./venv/bin/pip config <span class="nb">set</span> global.index-url https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple
</span></span></code></pre></div><h3 id="2-urlerrorconnectionrefusederror111-connection-refused在-docker-日志中大量出现无法下载翻译模型">2. (URLError(ConnectionRefusedError(111, &lsquo;Connection refused&rsquo;)),)在 docker 日志中大量出现，无法下载翻译模型<a hidden class="anchor" aria-hidden="true" href="#2-urlerrorconnectionrefusederror111-connection-refused在-docker-日志中大量出现无法下载翻译模型">#</a></h3>
<p>   Libretranslate 是基于 <code>argos-translate</code> 这个开源翻译模型开发的项目，内部仍然调用的是 argos-translate，argos-tanslate 下载一个 <code>index.json</code> 文件，然后根据你指定的需要支持的语言从 index.json 中获取下载路径。index.json 默认下载到 <code>~/.local/cache/argos-translate</code> 翻译模型默认下载保存到当前路径下 <code>db/session</code> 下。我出现的问题是从 docker 内部是无法正常下载index.json的，但是主机是可以正常下载的，因此我采用的方法是手动下载 index.json 并将其放到 Libretranslate 源码根目录下，然后在我要构建的 Dockerfile 末尾修改为：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Shell" data-lang="Shell"><span class="line"><span class="cl"><span class="c1"># 将主机当前目录的index.json放到容器的/root/.local/cache/argos-translate/下</span>
</span></span><span class="line"><span class="cl">RUN mkdir -p /root/.local/cache/argos-translate/
</span></span><span class="line"><span class="cl">RUN mv ./index.json /root/.local/cache/argos-translate/
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">EXPOSE <span class="m">5000</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 原本的--host * 不知道为什么我会报错，这里改成 0.0.0.0就没有报错了</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 这里我只需要中英互译就可以了</span>
</span></span><span class="line"><span class="cl">ENTRYPOINT <span class="o">[</span><span class="s2">&#34;libretranslate&#34;</span>, <span class="s2">&#34;--host&#34;</span>, <span class="s2">&#34;0.0.0.0&#34;</span>, <span class="s2">&#34;--load-only&#34;</span>，<span class="s2">&#34;zh,en&#34;</span><span class="o">]</span>
</span></span></code></pre></div><p>   这是参考的解决方案的<a href="https://community.libretranslate.com/t/failing-to-download-from-cloudflare-with-connectionrefusederror/960">链接</a>，这里提供我保存的<a href="/common/index.json">index.json文件</a></p>
<h3 id="3-启用-cuda-加速后进行翻译出现内部错误">3. 启用 cuda 加速后进行翻译出现内部错误<a hidden class="anchor" aria-hidden="true" href="#3-启用-cuda-加速后进行翻译出现内部错误">#</a></h3>
<p>   建议先进入 docker 内部使用 python执行 <code>torch.cuda.is_available()</code> 查看 CUDA 是否成功支持。</br>
   这里我的问题是我的 <strong>nvidia 驱动版本是 debian12 默认下载的535, CUDA 版本最高支持到 12.2</strong>, 而且我本地的 CUDA 环境是 11.8。<strong>Libretranslate默认构建镜像的 CUDA 版本是 12.4</strong>, 版本过高导致 torch 调用硬件失败。解决的方法是将 Libretranslate 构建时采用的基础镜像从 <code>FROM nvidia/cuda:12.4.1-devel-ubuntu20.04</code> 更换为 <code>FROM nvidia/cuda:12.2.0-devel-ubuntu20.04</code>。 注意一定要是 12 版本以上的，我之前采用与本地相同的 11.8 启动仍然失败了，<code>torch.cuda.is_available()</code> 的返回值是 True，但是运行时会出现动态链接库找不到的问题，当前这个版本好像默认要求 CUDA 版本大于 12。</p>
<h3 id="参考文献">参考文献<a hidden class="anchor" aria-hidden="true" href="#参考文献">#</a></h3>
<blockquote>
<p><a href="https://github.com/LibreTranslate/LibreTranslate">LibreTranslate的github</a> </br>
<a href="https://community.libretranslate.com/t/failing-to-download-from-cloudflare-with-connectionrefusederror/960">翻译模型下载失败参考解决方案</a> </br></p>
</blockquote>


  </div>

  <footer class="post-footer">
<nav class="paginav">
  <a class="next" href="https://againwq.github.io/posts/%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/goldendict/">
    <span class="title">下一页 »</span>
    <br>
    <span>Debian12中GoldenDict词典软件的使用</span>
  </a>
</nav>

  </footer>

<div id="vcomments"></div>


<script src='//unpkg.com/valine/dist/Valine.min.js'></script>
<script type="text/javascript">
    new Valine({
        el: '#vcomments',
        appId: 'mIHTzu4xPiVECrYmBvLyLJob-gzGzoHsz',
        appKey: 'NwaBNu8gh1X350R6NEsJrLMT',
        avatar: 'retro',
        placeholder: '说点什么吧...',
        visitor: 'true',
        avatar_cdn: 'https:\/\/cravatar.cn\/avatar\/'
    });

    let comments = document.getElementById('vcomments');
    comments.addEventListener("click", (e) => {      
        if(e.target.classList.contains('vsubmit')){
            const nick = document.querySelector("input[name='nick']").value;
            const mail = document.querySelector("input[type='email']").value;
            const reg = /^(\w-*\.*)+@(\w-?)+(\.\w{2,})+$/;
            if(nick.length < 2){
                alert('昵称长度不得小于3');
                e.stopPropagation();
            }
            if(!reg.test(mail)){
                alert('邮箱格式不正确');
                e.stopPropagation();
            }
        }
    }, true);
</script>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2025 <a href="https://againwq.github.io">Xu Qianchao&#39;s Blog</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = '复制';

        function copyingDone() {
            copybutton.innerHTML = '已复制！';
            setTimeout(() => {
                copybutton.innerHTML = '复制';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
