<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>docker on Xu Qianchao&#39;s Blog</title>
    <link>https://againwq.github.io/tags/docker/</link>
    <description>Recent content in docker on Xu Qianchao&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh</language>
    <lastBuildDate>Mon, 17 Mar 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://againwq.github.io/tags/docker/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>docker容器访问宿主机的docker环境</title>
      <link>https://againwq.github.io/posts/docker/docker%E5%AE%B9%E5%99%A8%E8%AE%BF%E9%97%AE%E5%AE%BF%E4%B8%BB%E6%9C%BA%E7%9A%84docker%E7%8E%AF%E5%A2%83/</link>
      <pubDate>Mon, 17 Mar 2025 00:00:00 +0000</pubDate>
      
      <guid>https://againwq.github.io/posts/docker/docker%E5%AE%B9%E5%99%A8%E8%AE%BF%E9%97%AE%E5%AE%BF%E4%B8%BB%E6%9C%BA%E7%9A%84docker%E7%8E%AF%E5%A2%83/</guid>
      <description>docker容器访问宿主机的docker环境</description>
      <content:encoded><![CDATA[<h2 id="一问题描述">一、问题描述</h2>
<p>   当我们使用docker容器的时候，有时候我们需要访问宿主机的docker环境，比如我们需要在容器中访问宿主机的docker服务，或者我们需要在容器中访问宿主机的docker网络。这时候我们就需要进行一些配置。</p>
<h2 id="二docker容器访问宿主机的docker环境">二、docker容器访问宿主机的docker环境</h2>
<p>   要想让docker容器访问宿主机器的docker环境，并可以在docker容器中使用docker命令，我们需要在docker容器中挂载宿主机的<strong>docker.sock文件和docker程序</strong>。docker.sock 文件是docker的socket文件，docker的api通过这个文件来进行通信。docker程序是docker的命令行程序，我们可以通过这个程序来操作docker，比如启动容器，停止容器等。在启动docker容器的时候，我们可以通过<code>-v</code>参数来挂载这两个文件，示例如下：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Shell" data-lang="Shell"><span class="line"><span class="cl">docker run -d --name controller --privileged 
</span></span><span class="line"><span class="cl">-v /usr/bin/docker:/usr/bin/docker <span class="c1"># 挂载docker程序</span>
</span></span><span class="line"><span class="cl">-v /var/run/docker.sock:/var/run/docker.sock <span class="c1"># 挂载docker socket文件</span>
</span></span><span class="line"><span class="cl">-t ubuntu:latest
</span></span></code></pre></div><p>   注意，这里我们使用了<code>--privileged</code>参数，这个参数是为了让docker容器拥有更高的权限，这样我们才能在docker容器中使用docker命令。如果不加这个参数，我们在docker容器中使用docker命令的时候会报错，提示权限不够。</br>
   还需要注意的是，这里必须保证宿主机操作系统的<strong>glibc版本</strong>和容器运行的镜像的glibc版本相同，否则在容器中执行docker命令会出现glibc版本冲突的问题。因此容器和宿主机最好采用相同的linux发行版本。</p>
<h2 id="三在docker容器内部访问其他容器的网络命名空间">三、在docker容器内部访问其他容器的网络命名空间</h2>
<h3 id="1-linux网络命名空间">1. Linux网络命名空间</h3>
<p>  Linux 的网络命名空间（Network Namespace）是一种内核提供的资源隔离机制，它为系统中的网络资源提供了独立的上下文环境，网络命名空间允许在同一物理主机上创建多个相互隔离的网络环境。每个网络命名空间都有自己独立的网络设备（如网卡）、IP 地址、路由表、防火墙规则等网络资源。不同网络命名空间中的网络配置相互独立，互不影响。例如，在一个命名空间中配置的 IP 地址，在其他命名空间中不会冲突，也无法直接访问。<strong>这就像是在同一台主机上虚拟出了多台独立的网络设备，每个设备都有自己的网络栈</strong>。</br>
   通过刚刚的配置我们可以在容器内部使用docker network去配置容器的网络，但有时候我们需要更加复杂的网络配置，比如为两个容器创建<strong>veth pair</strong>。这就需要我们在容器内部访问其他容器的<strong>Linux 网络命名空间</strong>。</p>
<h3 id="2-配置方法">2. 配置方法</h3>
<p>   一般的容器，如何没有使用host网络模式，都会有自己的网络命名空间，但是docker服务并没有把他们挂载到<code>/var/run/netns</code>目录下，因此使用<code>ip netns</code>等命令是无法访问到这些网络命名空间的。我们通常使用<code>docker inspect</code>获取容器的进程号，然后通过<code>/proc/$pid/ns/net</code>文件来访问容器的网络命名空间，因此我们可以通过挂载<code>/proc</code>目录来访问容器的网络命名空间。示例如下:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Shell" data-lang="Shell"><span class="line"><span class="cl">docker run -d --name controller --privileged 
</span></span><span class="line"><span class="cl">-v /usr/bin/docker:/usr/bin/docker
</span></span><span class="line"><span class="cl">-v /var/run/docker.sock:/var/run/docker.sock 
</span></span><span class="line"><span class="cl">-v /proc:/host_proc <span class="c1"># 挂载宿主机的/proc</span>
</span></span><span class="line"><span class="cl">-t ubuntu:latest
</span></span></code></pre></div><p>   为了防止<code>/proc</code>与容器内部的<code>/proc</code>目录冲突，这里我将其挂载为<code>/host_proc</code>。之后我们在容器内部将其他容器的命名空间链接到<code>/var/run/netns</code>目录下，就可以使用容器的pid直接访问容器的命名空间，而不需要输入完整的路径。比如我有一个pid为123的容器，示例命令如下</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Shell" data-lang="Shell"><span class="line"><span class="cl">ln -s /host_proc/123/ns/net /var/run/netns/123
</span></span></code></pre></div><h3 id="3-host网络模式">3. host网络模式</h3>
<p>   通过上面的配置我们已经让容器可以访问其他容器的命令空间了。但是我们想要进行为两个容器创建veth pair或者使用linux bridge去连接容器，建议使用<strong>host网络模式</strong>。host网络模式是docker的一种网络模式，使用host网络模式的容器会和宿主机共享网络命名空间，这样容器就可以直接访问宿主机的网络设备，这样当我们使用<code>ip link</code>或者<code>brctl</code>等命令创建网络设备的时候，保证我们是在宿主机上创建的，而不是在容器内部创建的。</p>
<h2 id="四注意事项">四、注意事项</h2>
<ul>
<li>容器和宿主机最好采用相同的linux发行版本，以避免glibc版本冲突的问题。</li>
<li>使用<code>--privileged</code>参数让docker容器拥有更高的权限，这样我们才能在docker容器中使用docker命令。</li>
<li>使用<code>host</code>网络模式，可以让容器和宿主机共享网络命名空间，这样容器就可以直接访问宿主机的网络设备。</li>
<li>如果想要创建veth pair或者使用linux bridge去连接容器，然后使用ping等命令测试网络连通性，记得需要在你的特权容器中进行如下配置，否则可能会出现网络连通性问题：</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Shell" data-lang="Shell"><span class="line"><span class="cl">sysctl -w net.bridge.bridge-nf-call-iptables<span class="o">=</span><span class="m">0</span> <span class="c1"># 关闭iptables的bridge-nf功能</span>
</span></span><span class="line"><span class="cl">sysctl -w net.ipv4.icmp_echo_ignore_all<span class="o">=</span><span class="m">0</span>  <span class="c1"># 开启icmp响应</span>
</span></span></code></pre></div><ul>
<li>上面的这些配置会破坏docker的隔离性，在生产环境中请慎重使用。</li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>本地docker部署libretranslate翻译模型并采用CUDA加速</title>
      <link>https://againwq.github.io/posts/docker/libretranslate%E7%9A%84docker%E7%89%88%E6%9C%AC%E9%83%A8%E7%BD%B2/</link>
      <pubDate>Tue, 12 Nov 2024 00:00:00 +0000</pubDate>
      
      <guid>https://againwq.github.io/posts/docker/libretranslate%E7%9A%84docker%E7%89%88%E6%9C%AC%E9%83%A8%E7%BD%B2/</guid>
      <description>Libtranslate的本地部署，并采用CUDA加速</description>
      <content:encoded><![CDATA[<h2 id="一libretanslate基本介绍">一、Libretanslate基本介绍</h2>
<p>   Libretanslate 是一个开源的，基于AI驱动的翻译软件，<a href="https://libretranslate.com/">官方网站</a>提供了在线的翻译功能，并且可以申请 api 密钥去调用 api 将翻译能力嵌入到我们自己的程序或者软件中。当然，<a href="https://github.com/LibreTranslate/LibreTranslate">官方的github</a>有详细的本地部署教程，如果有能力建议根据官方的 README 部署，本文是对可能遇到的一些问题的补充。本文采用的是 docker 部署，当然官方提供了直接通过 pip 包部署，读者可以根据自己的需求选择。效果图如下：</p>
<p><img loading="lazy" src="/images/Libretranslate%e7%bf%bb%e8%af%91%e6%95%88%e6%9e%9c.png" alt="libretranslate翻译效果"  />
</p>
<h2 id="二-docker-与-nvidia-docker-支持的前置条件">二. docker 与 nvidia docker 支持的前置条件</h2>
<p>   首先需要保证你的本地系统已经安装的 docker 环境，建议采用国内的源安装，比如清华源、阿里源等。同时建议配置docker镜像源防止由于网络问题无法拉取镜像。这里不提供安装配置命令，建议读者自行搜索相关资料。</br>
   使用 nvidia 的 docker 加速，需要读者本地拥有 nvidia 的显卡，并安装了显卡驱动。如果没有 nvidia 的显卡支持，可以跳过这一部分，进行 cpu 版本的本地部署。</br>
   首先要在自己的电脑上安装 nvidia docker 支持，参考的<a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html">官方地址</a>。根据你的 linux 发行版复制粘贴命令就行了，debian 发行版的安装命令如下：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Shell" data-lang="Shell"><span class="line"><span class="cl"><span class="c1"># 添加 apt 源</span>
</span></span><span class="line"><span class="cl">curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey <span class="p">|</span> <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg <span class="o">&amp;&amp;</span> <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list <span class="p">|</span> <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>sed <span class="s1">&#39;s#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g&#39;</span> <span class="p">|</span> <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">sudo sed -i -e <span class="s1">&#39;/experimental/ s/^#//g&#39;</span> /etc/apt/sources.list.d/nvidia-container-toolkit.list
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 更新源</span>
</span></span><span class="line"><span class="cl">sudo apt-get update
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 安装nvidia-container-toolkit</span>
</span></span><span class="line"><span class="cl">sudo apt-get install -y nvidia-container-toolkit
</span></span></code></pre></div><p>   然后对 docker 进行配置：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Shell" data-lang="Shell"><span class="line"><span class="cl">sudo nvidia-ctk runtime configure --runtime<span class="o">=</span>docker
</span></span><span class="line"><span class="cl">sudo systemctl restart docker
</span></span></code></pre></div><h2 id="三docker版本的libretranslate的本地部署">三、docker版本的libretranslate的本地部署</h2>
<p>   接下来我们进行部署。首先，我们需要在 github 上下载源码：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Shell" data-lang="Shell"><span class="line"><span class="cl">git clone git@github.com:LibreTranslate/LibreTranslate.git
</span></span></code></pre></div><h3 id="1-cpu版本libretranslate的部署">1. cpu版本libretranslate的部署</h3>
<p>   cpu 版本部署非常简单，在源码根路径下执行下面的命令</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Shell" data-lang="Shell"><span class="line"><span class="cl">docker compose -f docker-compose.yml up -d --build
</span></span></code></pre></div><p>   这个命令会根据 docker/Dockerfile 文件构建 libretranslate 镜像并部署在本地的 5000 端口。- -build 代表重新构建镜像。第一次构建好镜像后下一次可以把 - -build命令去掉，每次创建容器都会从网络上下载指定的翻译模型，因此 5000 端口并不能立即访问，可以通过 <code>docker stats</code> 查看容器的网络 IO 状态判断翻译模型是否下载完毕。</p>
<h3 id="2-gpu版本libretranslate的部署">2. GPU版本libretranslate的部署</h3>
<p>   部署gpu版本的 libretranslate 命令与上面相同，只是将 yml 文件为 docker-compose.cuda.yml。在部署之前，最好修改 docker/cuda.Dockerfile 文件将 cuda 的相关环境变量导出，大概在文件末尾的位置添加下面几行：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Shell" data-lang="Shell"><span class="line"><span class="cl"><span class="c1"># Depending on your cuda install you may need to uncomment this line to allow the container to access the cuda libraries</span>
</span></span><span class="line"><span class="cl"><span class="c1"># See: https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#post-installation-actions</span>
</span></span><span class="line"><span class="cl"><span class="c1"># ENV LD_LIBRARY_PATH=/usr/local/cuda/lib:/usr/local/cuda/lib64</span>
</span></span><span class="line"><span class="cl">ENV <span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span><span class="nv">$LD_LIBRARY_PATH</span>:/usr/local/cuda/lib64
</span></span><span class="line"><span class="cl">ENV <span class="nv">PATH</span><span class="o">=</span><span class="nv">$PATH</span>:/usr/local/cuda/bin
</span></span><span class="line"><span class="cl">ENV <span class="nv">CUDA_HOME</span><span class="o">=</span>/usr/local/cuda
</span></span></code></pre></div><p>   然后通过 <code>docker compose -f docker-compose.cuda.yml up -d --build</code>进行构建并部署即可。同样的，构建成功 docker 会启动在本地 5000 端口，每次创建容器都会从网络上下载指定的翻译模型。</p>
<h2 id="四可能遇到的问题">四、可能遇到的问题</h2>
<h3 id="1-构建镜像时apt和pip下载太慢">1. 构建镜像时apt和pip下载太慢</h3>
<p>   apt 和 pip 默认的官方源在国内访问不太稳定，可以在执行 <code>apt install</code>和 <code>pip install</code>之前更换镜像源为国内源，需要在对应的 Dockerfile中修改：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Shell" data-lang="Shell"><span class="line"><span class="cl"><span class="c1"># 更换apt源为清华源</span>
</span></span><span class="line"><span class="cl">RUN sed -i <span class="s1">&#39;s/archive.ubuntu.com/mirrors.tuna.tsinghua.edu.cn/g&#39;</span>  /etc/apt/sources.list
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">#更换pip源为清华源，应该添加在Dockerfile中pip下载之后的位置</span>
</span></span><span class="line"><span class="cl">RUN pip3 config <span class="nb">set</span> global.index-url https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># cpu版本中Dockerfile采用了venv</span>
</span></span><span class="line"><span class="cl">RUN ./venv/bin/pip config <span class="nb">set</span> global.index-url https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple
</span></span></code></pre></div><h3 id="2-urlerrorconnectionrefusederror111-connection-refused在-docker-日志中大量出现无法下载翻译模型">2. (URLError(ConnectionRefusedError(111, &lsquo;Connection refused&rsquo;)),)在 docker 日志中大量出现，无法下载翻译模型</h3>
<p>   Libretranslate 是基于 <code>argos-translate</code> 这个开源翻译模型开发的项目，内部仍然调用的是 argos-translate，argos-tanslate 下载一个 <code>index.json</code> 文件，然后根据你指定的需要支持的语言从 index.json 中获取下载路径。index.json 默认下载到 <code>~/.local/cache/argos-translate</code> 翻译模型默认下载保存到当前路径下 <code>db/session</code> 下。我出现的问题是从 docker 内部是无法正常下载index.json的，但是主机是可以正常下载的，因此我采用的方法是手动下载 index.json 并将其放到 Libretranslate 源码根目录下，然后在我要构建的 Dockerfile 末尾修改为：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Shell" data-lang="Shell"><span class="line"><span class="cl"><span class="c1"># 将主机当前目录的index.json放到容器的/root/.local/cache/argos-translate/下</span>
</span></span><span class="line"><span class="cl">RUN mkdir -p /root/.local/cache/argos-translate/
</span></span><span class="line"><span class="cl">RUN mv ./index.json /root/.local/cache/argos-translate/
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">EXPOSE <span class="m">5000</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 原本的--host * 不知道为什么我会报错，这里改成 0.0.0.0就没有报错了</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 这里我只需要中英互译就可以了</span>
</span></span><span class="line"><span class="cl">ENTRYPOINT <span class="o">[</span><span class="s2">&#34;libretranslate&#34;</span>, <span class="s2">&#34;--host&#34;</span>, <span class="s2">&#34;0.0.0.0&#34;</span>, <span class="s2">&#34;--load-only&#34;</span>，<span class="s2">&#34;zh,en&#34;</span><span class="o">]</span>
</span></span></code></pre></div><p>   这是参考的解决方案的<a href="https://community.libretranslate.com/t/failing-to-download-from-cloudflare-with-connectionrefusederror/960">链接</a>，这里提供我保存的<a href="/common/index.json">index.json文件</a></p>
<h3 id="3-启用-cuda-加速后进行翻译出现内部错误">3. 启用 cuda 加速后进行翻译出现内部错误</h3>
<p>   建议先进入 docker 内部使用 python执行 <code>torch.cuda.is_available()</code> 查看 CUDA 是否成功支持。</br>
   这里我的问题是我的 <strong>nvidia 驱动版本是 debian12 默认下载的535, CUDA 版本最高支持到 12.2</strong>, 而且我本地的 CUDA 环境是 11.8。<strong>Libretranslate默认构建镜像的 CUDA 版本是 12.4</strong>, 版本过高导致 torch 调用硬件失败。解决的方法是将 Libretranslate 构建时采用的基础镜像从 <code>FROM nvidia/cuda:12.4.1-devel-ubuntu20.04</code> 更换为 <code>FROM nvidia/cuda:12.2.0-devel-ubuntu20.04</code>。 注意一定要是 12 版本以上的，我之前采用与本地相同的 11.8 启动仍然失败了，<code>torch.cuda.is_available()</code> 的返回值是 True，但是运行时会出现动态链接库找不到的问题，当前这个版本好像默认要求 CUDA 版本大于 12。</p>
<h3 id="参考文献">参考文献</h3>
<blockquote>
<p><a href="https://github.com/LibreTranslate/LibreTranslate">LibreTranslate的github</a> </br>
<a href="https://community.libretranslate.com/t/failing-to-download-from-cloudflare-with-connectionrefusederror/960">翻译模型下载失败参考解决方案</a> </br></p>
</blockquote>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
